{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exploring the Shared Datasets in the LSST Science Platform\n",
    "<br>Owner(s): **Phil Marshall** ([@drphilmarshall](https://github.com/LSSTScienceCollaborations/StackClub/issues/new?body=@drphilmarshall)), \n",
    "<br>Last Verified to Run: **2018-08-05**\n",
    "<br>Verified Stack Release: **16.0**\n",
    "\n",
    "In this notebook we'll take a look at some of the datasets available on the LSST Science Platform. \n",
    "\n",
    "### Learning Objectives:\n",
    "\n",
    "After working through this tutorial you should be able to: \n",
    "1. Start figuring out which of the available datasets is going to be of most use to you in any given project; \n",
    "\n",
    "When it is finished, you should be able to:\n",
    "2. Plot the patches and tracts in a given dataset on the sky;\n",
    "3. List the available catalogs in a given dataset.\n",
    "\n",
    "### Logistics\n",
    "This notebook is intended to be runnable on `lsst-lsp-stable.ncsa.illinois.edu` from a local git clone of https://github.com/LSSTScienceCollaborations/StackClub.\n",
    "\n",
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need the `stackclub` package to be installed. If you are not developing this package, you can install it using `pip`, like this:\n",
    "```\n",
    "pip install git+git://github.com/LSSTScienceCollaborations/StackClub.git#egg=stackclub\n",
    "```\n",
    "If you are developing the `stackclub` package (eg by adding modules to it to support the Stack Club tutorial that you are writing, you'll need to make a local, editable installation. In the top level folder of the `StackClub` repo, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kadrlica/notebooks/.beavis/StackClub/Basics\r\n"
     ]
    }
   ],
   "source": [
    "! cd .. && python setup.py -q develop --user && cd -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When editing the `stackclub` package files, we want the latest version to be imported when we re-run the import command. To enable this, we need the %autoreload magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For accessing the datasets using the Butler, and then visualizing the results, we'll need the following modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %matplotlib ipympl\n",
    "\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import IFrame, display, Markdown\n",
    "\n",
    "import stackclub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.daf.persistence as dafPersist\n",
    "import lsst.daf.base as dafBase\n",
    "\n",
    "import lsst.afw.math as afwMath\n",
    "import lsst.afw.geom as afwGeom\n",
    "\n",
    "import lsst.afw.detection as afwDetect\n",
    "import lsst.afw.image as afwImage\n",
    "import lsst.afw.table as afwTable\n",
    "\n",
    "import lsst.afw.display as afwDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the Stack version that this notebook is running by using eups list -s on the terminal command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb-kadrlica-r18-1-0\r\n",
      "lsst_distrib          18.1.0     \tcurrent v18_1_0 setup\r\n"
     ]
    }
   ],
   "source": [
    "# What version of the Stack am I using?\n",
    "! echo $HOSTNAME\n",
    "! eups list -s | grep lsst_distrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Listing the Available Datasets\n",
    "First, let's look at what is currently available. There are two primary shared dataset folders in the LSP, the read-only `/datasets` folder, and the group-writeable folder `/projects/shared/datasets`. Let's see what's in there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`/projects/shared/data`:** These datasets are designed to be small test sets, ideal for tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/project/shared/data/beamsim',\n",
       " '/project/shared/data/ci_hsc',\n",
       " '/project/shared/data/ci_hsc_small',\n",
       " '/project/shared/data/COSMOS_catalogs',\n",
       " '/project/shared/data/csv.out',\n",
       " '/project/shared/data/DATA_ci_hsc',\n",
       " '/project/shared/data/desc_dc2',\n",
       " '/project/shared/data/diffim_template',\n",
       " '/project/shared/data/gaia_dr2',\n",
       " '/project/shared/data/gaia_dr2_1am',\n",
       " '/project/shared/data/hsc',\n",
       " '/project/shared/data/HSC_overlaps_db',\n",
       " '/project/shared/data/parq_gz.out',\n",
       " '/project/shared/data/parq.out',\n",
       " '/project/shared/data/PCW_2019',\n",
       " '/project/shared/data/ref_cats_indexed_twinkles.tar.gz',\n",
       " '/project/shared/data/test_data',\n",
       " '/project/shared/data/testdata_deblender',\n",
       " '/project/shared/data/tmp',\n",
       " '/project/shared/data/Twinkles_subset',\n",
       " '/project/shared/data/validation_data',\n",
       " '/project/shared/data/with-globular']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_datasets = ! ls -d /project/shared/data/* | grep -v README\n",
    "shared_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649M\t/project/shared/data/beamsim\n",
      "8.0G\t/project/shared/data/ci_hsc\n",
      "206M\t/project/shared/data/ci_hsc_small\n",
      "2.9G\t/project/shared/data/COSMOS_catalogs\n",
      "5.0M\t/project/shared/data/csv.out\n",
      "8.0G\t/project/shared/data/DATA_ci_hsc\n",
      "936G\t/project/shared/data/desc_dc2\n",
      "63G\t/project/shared/data/diffim_template\n",
      "1.1T\t/project/shared/data/gaia_dr2\n",
      "414G\t/project/shared/data/gaia_dr2_1am\n",
      "0\t/project/shared/data/hsc\n",
      "105M\t/project/shared/data/HSC_overlaps_db\n",
      "5.7M\t/project/shared/data/parq_gz.out\n",
      "5.3M\t/project/shared/data/parq.out\n",
      "0\t/project/shared/data/PCW_2019\n",
      "256K\t/project/shared/data/ref_cats_indexed_twinkles.tar.gz\n",
      "55G\t/project/shared/data/test_data\n",
      "262M\t/project/shared/data/testdata_deblender\n",
      "0\t/project/shared/data/tmp\n",
      "6.4G\t/project/shared/data/Twinkles_subset\n",
      "540G\t/project/shared/data/validation_data\n",
      "624M\t/project/shared/data/with-globular\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "shared_datasets=$( ls -d /project/shared/data/* | grep -v README )\n",
    "for dataset in $shared_datasets; do\n",
    "    du -sh $dataset\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`/datasets`:**\n",
    "These are typically much bigger: to measure the size, uncomment the second cell below and edit it to target the dataset you are interested in. Running `du` on all folders takes several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/datasets/all-sky',\n",
       " '/datasets/auxTel',\n",
       " '/datasets/comCam',\n",
       " '/datasets/ctio0m9',\n",
       " '/datasets/DC2',\n",
       " '/datasets/decam',\n",
       " '/datasets/des_sn',\n",
       " '/datasets/gapon',\n",
       " '/datasets/hsc',\n",
       " '/datasets/lsstCam',\n",
       " '/datasets/refcats',\n",
       " '/datasets/sdss',\n",
       " '/datasets/ts8']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = ! ls -d /datasets/* | grep -v USAGE | grep -v html\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# datasets=$( ls -d /datasets/* | grep -v USAGE | grep -v html )\n",
    "# for dataset in $datasets; do\n",
    "#     du -h $dataset\n",
    "# done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Sky Coverage\n",
    "In this section, we'll plot the available patches and tracts in a given dataset on the sky, following the LSST DESC tutorial [dm_butler_skymap.ipynb](https://github.com/LSSTDESC/DC2-analysis/blob/master/tutorials/dm_butler_skymap.ipynb). In fact, we will _import_ this notebook, so that we can re-use its functions. This operation is handled by the `stackclub.wimport` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: module was downloaded to {} but cound not be imported.\n",
      "Returning path to module: .downloads/dm_butler_skymap.ipynb\n"
     ]
    }
   ],
   "source": [
    "dm_butler_skymap_notebook = \"https://github.com/LSSTDESC/DC2-analysis/raw/master/tutorials/dm_butler_skymap.ipynb\"\n",
    "\n",
    "skymapper = stackclub.wimport(dm_butler_skymap_notebook, vb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> BUG: remote notebooks are not yet `wimport`-able. A workaround could be to import the downloaded file explicitly. This is not yet working, hence the commented out failed attempt below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys, os\n",
    "# import stackclub\n",
    "# sys.path.append(os.getcwd() + '/.downloads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dm_butler_skymap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can attempt to plot the available tracts, using the `plot_skymap_tract()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 91 tracts\n"
     ]
    }
   ],
   "source": [
    "# repo = \"/project/shared/data/Twinkles_subset/output_data_v2\"\n",
    "repo = \"/datasets/hsc/repo/rerun/DM-13666/WIDE\"\n",
    "butler = dafPersist.Butler(repo)\n",
    "\n",
    "# Glob the merged coadd folder for the tracts that have data.  Unfortunately, this information is not\n",
    "# directly accessible from the data butler.\n",
    "tracts = sorted([int(os.path.basename(x)) for x in\n",
    "                 glob.glob(os.path.join(repo, 'deepCoadd-results', 'merged', '*'))])\n",
    "\n",
    "# How many tracts do we have?\n",
    "print(\"Found {} tracts\".format(len(tracts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Uncomment this cell when the `wimport` bug is fixed (or avoided).\n",
    "\n",
    "# Now, loop over all the tracts, plotting them as gray, numbered, rectangles:\n",
    "ax = None\n",
    "for tract in tracts:\n",
    "    skyMap = butler.get('deepCoadd_skyMap')\n",
    "    ax = skymapper.plot_skymap_tract(skyMap, tract=tract, title='', ax=ax)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we took a first look at the datasets available to us in two shared directories in the LSST science platform filesystem."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
